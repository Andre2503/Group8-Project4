{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xPbwUKIGYPjPoMAS9LnPUq02t9xhvpB0",
      "authorship_tag": "ABX9TyNkUKF4KohU1WvyRk9ySs7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andre2503/Group8-Project4/blob/edrin/FakeNewsCNNV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yMx5ZkEjgXMb"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n"
      ]
    },
    {
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/FakeNews_Processed_Data.csv')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZKfnCDIiCKW",
        "outputId": "a8a66bdc-5df3-4145-e460-bf933003a195"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/FakeNews_Processed_Data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi5Aza40vn_c",
        "outputId": "c52002b3-15d2-4024-cd36-e7674bdc1aae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Data\n"
      ],
      "metadata": {
        "id": "ASxY_o0S-bOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Data\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/drive/My Drive/driveAndrea/Resources/FakeNews_Processed_Data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awHDDIjUvryE",
        "outputId": "e1b3b476-0fb5-4d9e-b8b5-185f64bd36c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          title_text  label\n",
            "0  law enforcement high alert following threats c...      1\n",
            "1                         post votes hillary already      1\n",
            "2  unbelievable obamas attorney general says char...      1\n",
            "3  bobby jindal raised hindu uses story christian...      0\n",
            "4  satan russia unvelis image terrifying new supe...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the Data"
      ],
      "metadata": {
        "id": "2cVOfBIr--8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Get basic information about the DataFrame\n",
        "print(df.info())\n",
        "\n",
        "# Summary statistics for numeric columns\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyEPpKlMxUiX",
        "outputId": "1d13153c-986e-4dd5-fb57-5b54aebbf8c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          title_text  label\n",
            "0  law enforcement high alert following threats c...      1\n",
            "1                         post votes hillary already      1\n",
            "2  unbelievable obamas attorney general says char...      1\n",
            "3  bobby jindal raised hindu uses story christian...      0\n",
            "4  satan russia unvelis image terrifying new supe...      1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 72134 entries, 0 to 72133\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   title_text  72133 non-null  object\n",
            " 1   label       72134 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "              label\n",
            "count  72134.000000\n",
            "mean       0.514404\n",
            "std        0.499796\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i'll get rid of the missing value\n",
        "df = df.dropna(subset=['title_text'])\n"
      ],
      "metadata": {
        "id": "_oCDHWb1xX5C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess The Data\n",
        "Text cleaning\n",
        "Tokenization\n",
        "Sequencing\n",
        "Padding"
      ],
      "metadata": {
        "id": "oItdmTaE_Qq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text processing\n",
        "texts = df['title_text'].astype(str)\n",
        "labels = df['label'].values\n",
        "\n",
        "# Initialise and fit the tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad the sequence\n",
        "max_sequence_length = 100\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length)\n"
      ],
      "metadata": {
        "id": "rG4KAWPzx_fw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spliting the Data\n",
        "Divivded data into clening and testing"
      ],
      "metadata": {
        "id": "rnN6pHtTAEVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "L0c_pdmgyHcy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the CNN Model\n",
        "Construct a CNN model suitable for text classification:"
      ],
      "metadata": {
        "id": "5aD5oIEzAze5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN Model\n",
        "import keras\n",
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 128, input_length=100))  # Adjust these parameters as needed\n",
        "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Another dropout layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "vI2oDwaYzTBi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "adjusted to implement early stopping"
      ],
      "metadata": {
        "id": "5kEOFZvwfUeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Stop training when the validation loss metric has stopped improving for 2 epochs.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    validation_data=(X_test, y_test),  # Use test set as validation data\n",
        "                    callbacks=[early_stopping])  # Add early stopping here\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nO0DzaQzjOG",
        "outputId": "6f6f817a-7deb-4a25-c389-76dc43594d22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1804/1804 [==============================] - 135s 74ms/step - loss: 0.3278 - accuracy: 0.8682 - val_loss: 0.1879 - val_accuracy: 0.9249\n",
            "Epoch 2/10\n",
            "1804/1804 [==============================] - 128s 71ms/step - loss: 0.1999 - accuracy: 0.9320 - val_loss: 0.1608 - val_accuracy: 0.9371\n",
            "Epoch 3/10\n",
            "1804/1804 [==============================] - 132s 73ms/step - loss: 0.1430 - accuracy: 0.9537 - val_loss: 0.1842 - val_accuracy: 0.9392\n",
            "Epoch 4/10\n",
            "1804/1804 [==============================] - 132s 73ms/step - loss: 0.1140 - accuracy: 0.9629 - val_loss: 0.2011 - val_accuracy: 0.9418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Evaluate the Model\n",
        "\n",
        "\n",
        "acc = model.evaluate(X_test, y_test)[1]\n",
        "print('Accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_H9iXmjzrJs",
        "outputId": "0a559cf9-7104-4371-d11d-cf4fb0406763"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "451/451 [==============================] - 7s 16ms/step - loss: 0.1608 - accuracy: 0.9371\n",
            "Accuracy: 0.9371317625045776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkNjGyhp42ue",
        "outputId": "41d87534-480e-4fa1-a83e-9b5a55bad4d2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "451/451 [==============================] - 6s 13ms/step - loss: 0.3533 - accuracy: 0.9465\n",
            "Test Accuracy: 0.9464892148971558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat GPT suggested using this to test the model to predict the likelihood that new text is fake news:\n",
        "\n",
        "new_texts = [\"Is South Africa Limiting Water for White People? Proposal Gets Pushback\"]\n",
        "seqs = tokenizer.texts_to_sequences(new_texts)\n",
        "padded_seqs = pad_sequences(seqs, maxlen=max_sequence_length)\n",
        "predictions = model.predict(padded_seqs)\n",
        "print(predictions)  # Closer to 1 indicates fake, closer to 0 indicates real\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcdsj-ns47L7",
        "outputId": "2fb5efcc-d21a-423e-aacc-c7fbc95b11fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step\n",
            "[[0.65148044]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "model.save('my_CNNmodelV2.h5')\n",
        "\n",
        "#Saving copy to Google drive\n",
        "model.save('/content/drive/My Drive/path_to_my_modelV2.h5', save_format='h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJSvLWFgc4Wl",
        "outputId": "74215f00-62ad-4f36-8a4c-61083d39ad63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/driveAndrea/Resources/CNNmodelV2.keras')\n",
        "#model = load_model('my_model.keras')"
      ],
      "metadata": {
        "id": "-FKr74KziyA0"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}