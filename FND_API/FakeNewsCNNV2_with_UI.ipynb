{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andre2503/Group8-Project4/blob/edrin/FakeNewsCNNV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INSTALL GRADIO TO RUN THE MODEL WITH A UI\n",
        "\n",
        "# !pip install -q gradio\n",
        "!pip install --upgrade gradio\n",
        "\n",
        "# Also gradio will need the following packages\n",
        "\n",
        "# !pip install kaleido\n",
        "# !pip install tiktoken\n",
        "# !pip install cohere\n",
        "# !pip install openai\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5AGChvYp0Ok",
        "outputId": "92d6b988-06db-4dd0-c290-6de0dec61816"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.13.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.108.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.33.0,>=0.29.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.32.0.post1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yMx5ZkEjgXMb"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZKfnCDIiCKW",
        "outputId": "c4f5afc4-e192-43f9-e35a-42485088c80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/FakeNews_Processed_Data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/FakeNews_Processed_Data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi5Aza40vn_c",
        "outputId": "95db43f2-44a0-4175-df73-4b8491c2ad5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASxY_o0S-bOf"
      },
      "source": [
        "# Loading the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awHDDIjUvryE",
        "outputId": "54905ecf-c7a2-4302-db99-115f1f3ba774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          title_text  label\n",
            "0  law enforcement high alert following threats c...      1\n",
            "1                         post votes hillary already      1\n",
            "2  unbelievable obamas attorney general says char...      1\n",
            "3  bobby jindal raised hindu uses story christian...      0\n",
            "4  satan russia unvelis image terrifying new supe...      1\n"
          ]
        }
      ],
      "source": [
        "# Loading the Data\n",
        "import pandas as pd\n",
        "\n",
        "# the data can be loading from any of the following paths\n",
        "\n",
        "# file_path = '/content/drive/My Drive/driveAndrea/Resources/FakeNews_Processed_Data.csv'\n",
        "file_path = '/content/drive/My Drive/Resources/FakeNews_Processed_Data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cVOfBIr--8p"
      },
      "source": [
        "# Understanding the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyEPpKlMxUiX",
        "outputId": "f3e6c9c1-e449-4857-ac59-6285d0b4dd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          title_text  label\n",
            "0  law enforcement high alert following threats c...      1\n",
            "1                         post votes hillary already      1\n",
            "2  unbelievable obamas attorney general says char...      1\n",
            "3  bobby jindal raised hindu uses story christian...      0\n",
            "4  satan russia unvelis image terrifying new supe...      1\n"
          ]
        }
      ],
      "source": [
        "# Look at the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get basic information about the DataFrame\n",
        "print(df.info())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM3TsccWyK3B",
        "outputId": "9e2ccaac-661a-422b-805b-9fcb9bf504d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 72134 entries, 0 to 72133\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   title_text  72133 non-null  object\n",
            " 1   label       72134 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for numeric columns\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiAmM2egyKNT",
        "outputId": "f48cf1dd-3dae-40ca-9512-11fc2b2c2a4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              label\n",
            "count  72134.000000\n",
            "mean       0.514404\n",
            "std        0.499796\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_oCDHWb1xX5C"
      },
      "outputs": [],
      "source": [
        "# i'll get rid of the missing value\n",
        "df = df.dropna(subset=['title_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oItdmTaE_Qq7"
      },
      "source": [
        "# Preprocess The Data\n",
        "Text cleaning\n",
        "Tokenization\n",
        "Sequencing\n",
        "Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rG4KAWPzx_fw"
      },
      "outputs": [],
      "source": [
        "# text processing\n",
        "texts = df['title_text'].astype(str)\n",
        "labels = df['label'].values\n",
        "\n",
        "# Initialise and fit the tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad the sequence\n",
        "max_sequence_length = 100\n",
        "data = pad_sequences(sequences, maxlen=max_sequence_length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnN6pHtTAEVv"
      },
      "source": [
        "# Spliting the Data\n",
        "Divivded data into clening and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L0c_pdmgyHcy"
      },
      "outputs": [],
      "source": [
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aD5oIEzAze5"
      },
      "source": [
        "# Build the CNN Model\n",
        "Construct a CNN model suitable for text classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI2oDwaYzTBi",
        "outputId": "2dee4187-6c99-4e8e-b632-5f03ad5ea1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 128)           82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1363349 (5.20 MB)\n",
            "Trainable params: 1363349 (5.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build the CNN Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 128, input_length=max_sequence_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nO0DzaQzjOG",
        "outputId": "18c7ca37-8094-4e81-97c7-fa83f2420462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1623/1623 [==============================] - 125s 76ms/step - loss: 0.2251 - accuracy: 0.9046 - val_loss: 0.1467 - val_accuracy: 0.9432\n",
            "Epoch 2/10\n",
            "1623/1623 [==============================] - 120s 74ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.1436 - val_accuracy: 0.9471\n",
            "Epoch 3/10\n",
            "1623/1623 [==============================] - 121s 75ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.1742 - val_accuracy: 0.9461\n",
            "Epoch 4/10\n",
            "1623/1623 [==============================] - 121s 74ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.2140 - val_accuracy: 0.9466\n",
            "Epoch 5/10\n",
            "1623/1623 [==============================] - 120s 74ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.2406 - val_accuracy: 0.9456\n",
            "Epoch 6/10\n",
            "1623/1623 [==============================] - 123s 76ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.2302 - val_accuracy: 0.9446\n",
            "Epoch 7/10\n",
            "1623/1623 [==============================] - 119s 73ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.2628 - val_accuracy: 0.9437\n",
            "Epoch 8/10\n",
            "1623/1623 [==============================] - 118s 73ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.3197 - val_accuracy: 0.9459\n",
            "Epoch 9/10\n",
            "1623/1623 [==============================] - 120s 74ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.3657 - val_accuracy: 0.9430\n",
            "Epoch 10/10\n",
            "1623/1623 [==============================] - 121s 75ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3860 - val_accuracy: 0.9447\n"
          ]
        }
      ],
      "source": [
        "# Training the Model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_H9iXmjzrJs",
        "outputId": "b669520b-af28-4a37-b9b7-1c4a10924a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "451/451 [==============================] - 7s 15ms/step - loss: 0.3955 - accuracy: 0.9443\n",
            "Accuracy: 0.9442711472511292\n"
          ]
        }
      ],
      "source": [
        "# prompt: # Evaluate the Model\n",
        "\n",
        "\n",
        "acc = model.evaluate(X_test, y_test)[1]\n",
        "print('Accuracy:', acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkNjGyhp42ue",
        "outputId": "0ae5e450-a99e-4550-f3ed-450921b5a651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "451/451 [==============================] - 6s 13ms/step - loss: 0.3955 - accuracy: 0.9443\n",
            "Test Accuracy: 0.9442711472511292\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Fcdsj-ns47L7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e73b03-bc19-4272-e474-2974b238e613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "[[0.48055273]]\n"
          ]
        }
      ],
      "source": [
        "# Chat GPT suggested using this to test the model to predict the likelihood that new text is fake news:\n",
        "\n",
        "news_texts = [\"Is South Africa Limiting Water for White People? Proposal Gets Pushback\"]\n",
        "\n",
        "seqs = tokenizer.texts_to_sequences(news_texts)\n",
        "padded_seqs = pad_sequences(seqs, maxlen=max_sequence_length)\n",
        "predictions = model.predict(padded_seqs)\n",
        "print(predictions)  # Closer to 1 indicates fake, closer to 0 indicates real\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJSvLWFgc4Wl",
        "outputId": "65049759-976d-413d-f733-e7ccc5a43154"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Saving the model\n",
        "model.save('my_CNNmodel.h5')\n",
        "\n",
        "#Saving copy to Google drive\n",
        "model.save('/content/drive/My Drive/path_to_my_model.h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FKr74KziyA0"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/My Drive/driveAndrea/Resources/CNNmodel.keras')\n",
        "#model = load_model('my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik4ajK9WpzXQ"
      },
      "source": [
        "# UI CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you run the following code (cells) you must install gradio package and all packages it requires.\n",
        "\n",
        "Please go to the first cell in this notebook and install one by one all the packages to run the UI.\n",
        "\n",
        "Thank you."
      ],
      "metadata": {
        "id": "MZwCfnsmA3r3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "E0GLE_atpzXR",
        "outputId": "a1732dbd-29f5-4e6d-da59-ea69af1120f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e50e68e299cb320d29.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e50e68e299cb320d29.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# THE FOLLOWING CODE IS FOR THE UI\n",
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "\n",
        "# the news_analyzer function is the main function of the app.\n",
        "# it takes the news tittle and body as input and return the\n",
        "# result as output.\n",
        "def news_analyzer(news_tittle, news_body):\n",
        "    ok_data = input_validation(news_tittle, news_body)\n",
        "    if ok_data == 1:\n",
        "       # get the data ready for the model\n",
        "       transformed_data = data_normalization(news_tittle, news_body)\n",
        "       # get the prediction answer from the model\n",
        "       model_answer = prediction_answer(transformed_data)\n",
        "       float_answer = model_answer[0][0]\n",
        "       # set the answer to be readable\n",
        "       answer_translate = transformed_answer(float_answer)\n",
        "       answer = f\"The news is {answer_translate} \"\n",
        "    else:\n",
        "        answer = \"Please fill the form with valid data\"\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# the data_normalization function clean and normalize the data as\n",
        "# our model requires.\n",
        "def data_normalization(news_title, news_body):\n",
        "    full_news = news_title + news_body\n",
        "    full_news = lower_case(full_news)\n",
        "    clean_text = delete_special_characters(full_news)\n",
        "    significant_words = delete_stop_words(clean_text)\n",
        "    standardized_data = significant_words\n",
        "    # print(\"data_normalization\")\n",
        "    return standardized_data\n",
        "\n",
        "\n",
        "# the delete_special_characters function delete all the\n",
        "# special characters in the text.\n",
        "def delete_special_characters(text):\n",
        "    special_characters_deleted = re.sub(r\"[^\\w\\s]|[\\d]\", \"\", text)\n",
        "    # print(\"delete_special_characters\")\n",
        "    return special_characters_deleted\n",
        "\n",
        "\n",
        "# the delete_stop_words function delete all the insignificant words (stop words)\n",
        "# The default list of English stop words includes:\n",
        "# a, an, and, are, as, at, be, but, by, for, if, in, into, is, it, no, not, of, on, or, such,\n",
        "# that, the, their, then, there, these, they, this, to, was, will and with.\n",
        "def delete_stop_words(text):\n",
        "    # create a list\n",
        "    list_significant_words = []\n",
        "    # stop_words get a list of common English stop words provided by nltk\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    # word_tokens is a list of all words in the text.\n",
        "    # word_tokenize is a function provided by nltk\n",
        "    # to split the text into words.\n",
        "    word_tokens = word_tokenize(text)\n",
        "    # significant_word is a variable of  non-stop word in the text.\n",
        "    significant_word = [word for word in word_tokens if not word in stop_words]\n",
        "    # list_significant_words is a string of all significant words in the text.\n",
        "    list_significant_words = \" \".join(significant_word)\n",
        "    # print(\"delete_stop_words\")\n",
        "    return list_significant_words\n",
        "\n",
        "# change whole text to lower case\n",
        "def lower_case(text):\n",
        "    lower_case_text = text.lower()\n",
        "    return lower_case_text\n",
        "\n",
        "# return the answer from the model\n",
        "def prediction_answer(data_transformed):\n",
        "    # load the fake news detector model (fnd_model)\n",
        "\n",
        "    # new_texts = [\"This is a test\"]\n",
        "    new_texts = [data_transformed]\n",
        "\n",
        "    seqs = tokenizer.texts_to_sequences(new_texts)\n",
        "    padded_seqs = pad_sequences(seqs, maxlen=max_sequence_length)\n",
        "    answer_prediction_model = model.predict(padded_seqs)\n",
        "    return answer_prediction_model\n",
        "\n",
        "# the transformed_answer function give us a str final answer for the app\n",
        "# to show in our UI\n",
        "def transformed_answer(model_answer):\n",
        "    if model_answer > 0.50:\n",
        "        answer_transformed = \"legitimate\"\n",
        "    else:\n",
        "        answer_transformed = \"fake\"\n",
        "    return answer_transformed\n",
        "\n",
        "# clean_textboxes clean the textboxes from the app form\n",
        "def clean_textboxes():\n",
        "    return \"\", \"\"\n",
        "\n",
        "# input_validation function check that the data required for analizis is complete\n",
        "def input_validation(title_news, text_news):\n",
        "    if title_news.isnumeric() or text_news.isnumeric() or text_news == \"\" or title_news == \"\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "# build the UI\n",
        "with gr.Blocks() as FND_app:\n",
        "    app_title = \"Fake News Detector\"\n",
        "    description_a = \"This app use a ML model to detect fake news\"\n",
        "    description_b = \"Please fill the form and click **Analize** \"\n",
        "    gr.Markdown(description_a, show_label=False)\n",
        "    gr.Markdown(description_b, show_label=False)\n",
        "    gr.Label(app_title, show_label=False)\n",
        "    tittle_news = gr.Textbox(placeholder=\"News Title here...\", label=\"News Title\")\n",
        "    body_news = gr.Textbox(\n",
        "        placeholder=\"News Text here...\", label=\"News Text\", max_lines=10\n",
        "    )\n",
        "    # output = gr.Textbox(label=\"Output Box\")\n",
        "    output = gr.Label(label=\"Answer\", show_label=False)\n",
        "    with gr.Row():\n",
        "        greet_btn = gr.Button(\"Analyze\")\n",
        "        clean_btn = gr.Button(\"Clear\")\n",
        "\n",
        "    greet_btn.click(\n",
        "        fn=news_analyzer,\n",
        "        inputs=[tittle_news, body_news],\n",
        "        outputs=output,\n",
        "        api_name=\"FND_API\",\n",
        "    )\n",
        "\n",
        "    clean_btn.click(\n",
        "        fn=clean_textboxes,\n",
        "        outputs=[tittle_news, body_news],\n",
        "        api_name=\"FND_API\",\n",
        "    )\n",
        "\n",
        "FND_app.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # #test with the UI functions deactivated\n",
        "# news_tittle =\"***********************************************************************Shares fall as benchmark books strongest annual gain in two years\"\n",
        "# news_body = \"The local benchmark sank in its final session of the year, as investors looked to lock in some profits to cap off a solid December run. Australian shares sank on the final trading day of 2023 on Friday, but closed the year up 7.8 per cent â€” the best annual performance since 2021.\"\n",
        "# respuesta = news_analyzer(news_tittle, news_body)\n",
        "# print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzJnxrKBdsRw",
        "outputId": "bfdd1241-f867-4e18-c7a1-f793936f01a4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "The news is fake \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}